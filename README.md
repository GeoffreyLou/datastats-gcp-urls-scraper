# ğŸš€ Datastats GCP Urls Scraper

This repository is a part of the **Datastats** x **GCP** project.


## âœ¨ Datastats x GCP purpose

The goal of this project is to collect daily job offers informations in data-related professions, in order to monitor market trends and the most in-demand technologies.


## ğŸ¤” What is Urls Scrapper ?

This is a â€œCloud Run Jobâ€ that executes with a job name as an input variable. It then generates a web page containing job offers for the last 24 hours in France. On each job offer, a check is made to ensure that the job name is present in the title. Each job offer that matches the job name is set aside via its url for later retrieval. 

This architecture enables the container to operate independently and autonomously, so that it can be parallelized with different job names. 


## ğŸ‘·ğŸ»â€â™€ï¸ Architecture

- A Cloud Scheduler triggers a Workflow and passes the job to scrape as an environment variable.
- The Cloud Run Job scrapes job offer websites and stores URLs in two lists: one with all scraped jobs and one with only the jobs that match the specified variable.
- The lists are stored in JSON files and uploaded to buckets according to their purpose: one will be used by another Cloud Run Job to deduplicate and retrieve job information, and the other will be analyzed at the end of the month by a Large Language Model (LLM) to add new jobs to scrape.
- Additionally, statistical data is inserted into an SQL table to monitor scraping performance.

![Urls Scrapper global architecture](assets/urls_scrapper.png)


## ğŸ“ Repository tree

```shell
datastats-gcp-urls-scraper/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ dependabot.yml
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ build_and_deploy.yml
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ urls_scrapper.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config_loader.py
â”‚       â”œâ”€â”€ datastats_utils.py
â”‚       â”œâ”€â”€ gcp_utils.py
â”‚       â”œâ”€â”€ pg_utils.py
â”‚       â”œâ”€â”€ urls_scrapper.py
â”‚       â””â”€â”€ webpage_generator.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ uv.lock
```

## ğŸ’¡ What's next ? 

Planned improvements for this repository:
- Add tests 